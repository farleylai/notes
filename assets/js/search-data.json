{
  
    
        "post0": {
            "title": "SLURM Out of Memory with LMDB",
            "content": "TL; DR . SLURM monitors the total resident memory (RSS) consumed by all the task processes (incl. dataloader workers) | pin_memory=True increases RSS significantly and may cause leaks with mmap based LMDB, pushing to the memory limit sooner | PyTorch FastDataLoader or DataLoader created with persistent_workers=True is going to accumulate RSS with workers that never reset MMAP based storage such as LMDB env across epochs | . When it comes to training deep learning models, the I/O storage capacity and transfer bandwidth are ususally the bottleneck. While HDF5 is efficient to load the entire dataset for training, it is limited to the system memory capacity, typically up to hunderds of GB. On the other hand, memory mampped (MMAP) storage allows data access beyond system memory constraints. One popular implementation is LMDB, providing numerous language bindings including Python. It is tempting to replace HDF5 with LMDB for super large dataset loading and access. When running locally, potential memory allocation issues may not emerge to the surface as modern computer systems support disk swap space in case the process consumes more than available memory. However, training deep models could take days or longer and it is not uncommon to set up the training job in a high performance coomputing cluster such as SLURM. To submit a job to the SLURM cluster, the memory usage must be specified beforehand and at runtime, the memory usage is monitored according to the Resident Set Size (RSS) statistics. Unfortunately, the same training process on SLRUM is now subject to out of memory error because the swap space may not be available for SLURM tasks and MMAP based LMDB may grow the RSS over time beyond the usage limit. The following pytest snippet demonstrates the task RSS is increasing with LMDB access to a huage dataset over epochs: . import os import sys import random import pytest import torch from torch.utils.data import DataLoader from time import time from tqdm import tqdm print() KB = 2**10 MB = 2**10 * KB GB = 2**10 * MB def rss_usage(breakdown=False): import psutil proc = psutil.Process(os.getpid()) RSS = [] RSS.append((os.getpid(), proc.memory_info().rss)) for child in proc.children(recursive=True): RSS.append((child.pid, child.memory_info().rss)) rss = sum(mem for _, mem in RSS) return (rss, RSS) if breakdown else rss def test_rss(): print(sys.argv) argv = sys.argv sys.argv = [argv[1]] import lmdb from utils.utils import FastDataLoader from dataset.lmdb_dataset import UCF101LMDB_2CLIP from main_nce import parse_args, get_transform args = parse_args() sys.argv = argv lmdb_root = &quot;/mnt/ssd/dataset/ucf101/lmdb&quot; lmdb_path = f&quot;{lmdb_root}/UCF101/ucf101_frame.lmdb&quot; trans = get_transform(&#39;train&#39;, args) ucf101 = UCF101LMDB_2CLIP(db_path=lmdb_path, mode=&#39;train&#39;, transform=trans, num_frames=32, ds=1, return_label=True) print(f&quot;Created UCF101 2clip dataset of size {len(ucf101)}&quot;) dataloader = FastDataLoader(ucf101, batch_size=32, shuffle=True, num_workers=4, persistent_workers=False, pin_memory=not True, sampler=None, drop_last=True) batches = 8 for epoch in range(3): rss = rss_usage() print(f&quot;[e{epoch:02d}] RSS: {rss / GB:.2f} GB&quot;) for idx, (input_seq, label) in tqdm(enumerate(dataloader), total=len(dataloader), disable=True): if idx % 4 == 0: rss, RSS = rss_usage(True) for pid, mem in RSS: print(f&quot;[e{epoch:02d}][b{idx:02d}][{pid}] consumes {mem / GB:.2f} GB&quot;) print(f&quot;[e{epoch:02d}][b{idx:02d}] RSS: {rss / GB:.2f} GB&quot;) if idx == batches: break . [e00] RSS: 2.56 GB [e00][b00][14023] consumes 1.08 GB [e00][b00][14055] consumes 0.49 GB [e00][b00][14071] consumes 0.81 GB [e00][b00][14087] consumes 0.83 GB [e00][b00][14103] consumes 0.84 GB [e00][b00] RSS: 4.07 GB [e00][b04][14023] consumes 1.08 GB [e00][b04][14055] consumes 0.78 GB [e00][b04][14071] consumes 0.90 GB [e00][b04][14087] consumes 0.64 GB [e00][b04][14103] consumes 0.80 GB [e00][b04] RSS: 4.20 GB [e00][b08][14023] consumes 1.08 GB [e00][b08][14055] consumes 0.97 GB [e00][b08][14071] consumes 1.00 GB [e00][b08][14087] consumes 0.66 GB [e00][b08][14103] consumes 1.24 GB [e00][b08] RSS: 4.95 GB [e01] RSS: 4.97 GB [e01][b00][14023] consumes 1.08 GB [e01][b00][14055] consumes 0.66 GB [e01][b00][14071] consumes 0.92 GB [e01][b00][14087] consumes 0.66 GB [e01][b00][14103] consumes 0.80 GB [e01][b00] RSS: 4.12 GB [e01][b04][14023] consumes 1.08 GB [e01][b04][14055] consumes 0.80 GB [e01][b04][14071] consumes 0.99 GB [e01][b04][14087] consumes 1.04 GB [e01][b04][14103] consumes 1.03 GB [e01][b04] RSS: 4.93 GB [e01][b08][14023] consumes 1.08 GB [e01][b08][14055] consumes 0.87 GB [e01][b08][14071] consumes 1.05 GB [e01][b08][14087] consumes 1.19 GB [e01][b08][14103] consumes 1.07 GB [e01][b08] RSS: 5.26 GB [e02] RSS: 5.29 GB [e02][b00][14023] consumes 1.08 GB [e02][b00][14055] consumes 0.85 GB [e02][b00][14071] consumes 1.06 GB [e02][b00][14087] consumes 1.09 GB [e02][b00][14103] consumes 1.09 GB [e02][b00] RSS: 5.17 GB [e02][b04][14023] consumes 1.08 GB [e02][b04][14055] consumes 0.92 GB [e02][b04][14071] consumes 1.12 GB [e02][b04][14087] consumes 0.86 GB [e02][b04][14103] consumes 1.14 GB [e02][b04] RSS: 5.12 GB [e02][b08][14023] consumes 1.08 GB [e02][b08][14055] consumes 0.97 GB [e02][b08][14071] consumes 1.19 GB [e02][b08][14087] consumes 0.93 GB [e02][b08][14103] consumes 1.23 GB [e02][b08] RSS: 5.39 GB . The root cause is the LMDB Python API to access database records as follows may not release the mapped memory timely on completion to reduce the runtime RSS. . class UCF101LMDB_2CLIP(object): ... print(&#39;Loading LMDB from %s, split:%d&#39; % (self.db_path, self.which_split)) self.env = lmdb.open(self.db_path, subdir=os.path.isdir(self.db_path), readonly=True, lock=False, readahead=False, meminit=False) ... def __getitem__(self, index): vpath, vlen, vlabel, vname = self.video_subset.iloc[index] env = self.env with env.begin(write=False) as txn: raw = msgpack.loads(txn.get(self.get_video_id[vname].encode(&#39;ascii&#39;))) . Worse, the FastLoader never recreates dataset iterator workers that involes the LMDB env and will grow RSS over epochs due to increasing MMAP access. If using the vanilla DataLoader, make sure to set persistent_workers=False in case of a similar memory leak. Nonetheless, sufficient memory must be allocated at least for peak usage in one epoch. This serves as the workaround. .",
            "url": "https://farley.metax.vision/blog/slurm/lmdb/leak/2022/03/02/lmdb.html",
            "relUrl": "/blog/slurm/lmdb/leak/2022/03/02/lmdb.html",
            "date": " • Mar 2, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Identify hillside regionos on a map view",
            "content": "Hillside regions on a map are those marked in shades with dense contour lines passing through. Identifying those hillsides regions in a mask while filtering out other distracting elements can be useful for location based applicaitons. The following code snippet demonstrates the combination of blurring and OTSU thresholding of a map view suffices to find the hillsides given a map view. . from matplotlib import pyplot as plt import numpy as np import cv2 as cv import base64 img = cv.imread(&#39;/content/drive/MyDrive/Colab Notebooks/assets/contour.png&#39;, cv.IMREAD_GRAYSCALE) ksz = 21 blurGau = cv.GaussianBlur(img, (ksz, ksz), 0) blurMedian = cv.medianBlur(img, ksz) fig, axs = plt.subplots(2, 3, figsize=(15, 8)) for row, (blur, blurred) in enumerate([(&#39;GaussianBlur&#39;, blurGau), (&#39;MedianBlur&#39;, blurMedian)]): (T, threshOtsu) = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY+cv.THRESH_OTSU) images = [img, blurred, threshOtsu] titles = [&quot;Orginal&quot;, blur, f&quot;{blur} THRESH_OTSU&quot;] for col, (image, title) in enumerate(zip(images, titles)): ax = axs[row, col] ax.imshow(image, &#39;gray&#39;) ax.set_title(title) ax.set_xticks([]) ax.set_yticks([]) plt.tight_layout() plt.show() .",
            "url": "https://farley.metax.vision/blog/2022/03/01/maps.html",
            "relUrl": "/blog/2022/03/01/maps.html",
            "date": " • Mar 1, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Object Detection Metrics and Their Use Cases",
            "content": "mAP . mmAP . References . 淺析經典目標檢測評價指標--mmAP（一） 淺析經典目標檢測評價指標--mmAP（二） .",
            "url": "https://farley.metax.vision/computer%20vision/object%20detection/2021/01/09/detection_metrics.html",
            "relUrl": "/computer%20vision/object%20detection/2021/01/09/detection_metrics.html",
            "date": " • Jan 9, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Migration to fastpages Backend",
            "content": "Seamless Deployment on GitHub Pages . Built with fastpages, an easy to use blogging platform with extra features for Jupyter Notebooks. . . It automates the process of creating blog posts via GitHub Actions, so there is no need to fuss with conversion scripts. In summary, fastpages facilitates automatic deployment with GitHub Actions. A dedicated &lt;username&gt;.github.io repo is no longer necessary. . Editing on Google/Colab with Access to GPU/TPU . Each post can be either in Jupyter notebook or markdown. If in Jupyter notebook, the editing and running are well integrated with Google/Colab, implying interactive computation with access to GPU/TPU for free as follows. . import sys import platform import torch print(f&quot;sys.version={sys.version}&quot;) print(f&quot;platform={platform.platform()}&quot;) print(f&quot;torch: {torch.__version__}&quot;) print(f&quot;torch.cuda: {torch.cuda.device_count()} GPUs, version={torch.version.cuda}&quot;) !nvcc --version !nvidia-smi !pip list . sys.version=3.6.9 (default, Oct 8 2020, 12:12:24) [GCC 8.4.0] platform=Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic torch: 1.7.0+cu101 torch.cuda: 1 GPUs, version=10.1 nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2019 NVIDIA Corporation Built on Sun_Jul_28_19:07:16_PDT_2019 Cuda compilation tools, release 10.1, V10.1.243 Tue Dec 8 05:15:42 2020 +--+ | NVIDIA-SMI 455.45.01 Driver Version: 418.67 CUDA Version: 10.1 | |-+-+-+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla T4 Off | 00000000:00:04.0 Off | 0 | | N/A 47C P8 10W / 70W | 10MiB / 15079MiB | 0% Default | | | | ERR! | +-+-+-+ +--+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +--+ Package Version -- absl-py 0.10.0 alabaster 0.7.12 albumentations 0.1.12 altair 4.1.0 argon2-cffi 20.1.0 asgiref 3.3.1 astor 0.8.1 astropy 4.1 astunparse 1.6.3 async-generator 1.10 atari-py 0.2.6 atomicwrites 1.4.0 attrs 20.3.0 audioread 2.1.9 autograd 1.3 Babel 2.9.0 backcall 0.2.0 beautifulsoup4 4.6.3 bleach 3.2.1 blis 0.4.1 bokeh 2.1.1 Bottleneck 1.3.2 branca 0.4.1 bs4 0.0.1 CacheControl 0.12.6 cachetools 4.1.1 catalogue 1.0.0 certifi 2020.11.8 cffi 1.14.3 chainer 7.4.0 chardet 3.0.4 click 7.1.2 cloudpickle 1.3.0 cmake 3.12.0 cmdstanpy 0.9.5 colorlover 0.3.0 community 1.0.0b1 contextlib2 0.5.5 convertdate 2.3.0 coverage 3.7.1 coveralls 0.5 crcmod 1.7 cufflinks 0.17.3 cupy-cuda101 7.4.0 cvxopt 1.2.5 cvxpy 1.0.31 cycler 0.10.0 cymem 2.0.4 Cython 0.29.21 daft 0.0.4 dask 2.12.0 dataclasses 0.8 datascience 0.10.6 debugpy 1.0.0 decorator 4.4.2 defusedxml 0.6.0 descartes 1.1.0 dill 0.3.3 distributed 1.25.3 Django 3.1.3 dlib 19.18.0 dm-tree 0.1.5 docopt 0.6.2 docutils 0.16 dopamine-rl 1.0.5 earthengine-api 0.1.238 easydict 1.9 ecos 2.0.7.post1 editdistance 0.5.3 en-core-web-sm 2.2.5 entrypoints 0.3 ephem 3.7.7.1 et-xmlfile 1.0.1 fa2 0.3.5 fancyimpute 0.4.3 fastai 1.0.61 fastdtw 0.3.4 fastprogress 1.0.0 fastrlock 0.5 fbprophet 0.7.1 feather-format 0.4.1 filelock 3.0.12 firebase-admin 4.4.0 fix-yahoo-finance 0.0.22 Flask 1.1.2 flatbuffers 1.12 folium 0.8.3 future 0.16.0 gast 0.3.3 GDAL 2.2.2 gdown 3.6.4 gensim 3.6.0 geographiclib 1.50 geopy 1.17.0 gin-config 0.3.0 glob2 0.7 google 2.0.3 google-api-core 1.16.0 google-api-python-client 1.7.12 google-auth 1.17.2 google-auth-httplib2 0.0.4 google-auth-oauthlib 0.4.2 google-cloud-bigquery 1.21.0 google-cloud-bigquery-storage 1.1.0 google-cloud-core 1.0.3 google-cloud-datastore 1.8.0 google-cloud-firestore 1.7.0 google-cloud-language 1.2.0 google-cloud-storage 1.18.1 google-cloud-translate 1.5.0 google-colab 1.0.0 google-pasta 0.2.0 google-resumable-media 0.4.1 googleapis-common-protos 1.52.0 googledrivedownloader 0.4 graphviz 0.10.1 grpcio 1.33.2 gspread 3.0.1 gspread-dataframe 3.0.8 gym 0.17.3 h5py 2.10.0 HeapDict 1.0.1 holidays 0.10.3 holoviews 1.13.5 html5lib 1.0.1 httpimport 0.5.18 httplib2 0.17.4 httplib2shim 0.0.3 humanize 0.5.1 hyperopt 0.1.2 ideep4py 2.0.0.post3 idna 2.10 image 1.5.33 imageio 2.4.1 imagesize 1.2.0 imbalanced-learn 0.4.3 imblearn 0.0 imgaug 0.2.9 importlib-metadata 2.0.0 importlib-resources 3.3.0 imutils 0.5.3 inflect 2.1.0 iniconfig 1.1.1 intel-openmp 2020.0.133 intervaltree 2.1.0 ipykernel 4.10.1 ipython 5.5.0 ipython-genutils 0.2.0 ipython-sql 0.3.9 ipywidgets 7.5.1 itsdangerous 1.1.0 jax 0.2.6 jaxlib 0.1.57+cuda101 jdcal 1.4.1 jedi 0.17.2 jieba 0.42.1 Jinja2 2.11.2 joblib 0.17.0 jpeg4py 0.1.4 jsonschema 2.6.0 jupyter 1.0.0 jupyter-client 5.3.5 jupyter-console 5.2.0 jupyter-core 4.7.0 jupyterlab-pygments 0.1.2 kaggle 1.5.9 kapre 0.1.3.1 Keras 2.4.3 Keras-Preprocessing 1.1.2 keras-vis 0.4.1 kiwisolver 1.3.1 knnimpute 0.1.0 korean-lunar-calendar 0.2.1 librosa 0.6.3 lightgbm 2.2.3 llvmlite 0.31.0 lmdb 0.99 lucid 0.3.8 LunarCalendar 0.0.9 lxml 4.2.6 Markdown 3.3.3 MarkupSafe 1.1.1 matplotlib 3.2.2 matplotlib-venn 0.11.6 missingno 0.4.2 mistune 0.8.4 mizani 0.6.0 mkl 2019.0 mlxtend 0.14.0 more-itertools 8.6.0 moviepy 0.2.3.5 mpmath 1.1.0 msgpack 1.0.0 multiprocess 0.70.11.1 multitasking 0.0.9 murmurhash 1.0.4 music21 5.5.0 natsort 5.5.0 nbclient 0.5.1 nbconvert 5.6.1 nbformat 5.0.8 nest-asyncio 1.4.3 networkx 2.5 nibabel 3.0.2 nltk 3.2.5 notebook 5.3.1 np-utils 0.5.12.1 numba 0.48.0 numexpr 2.7.1 numpy 1.18.5 nvidia-ml-py3 7.352.0 oauth2client 4.1.3 oauthlib 3.1.0 okgrade 0.4.3 opencv-contrib-python 4.1.2.30 opencv-python 4.1.2.30 openpyxl 2.5.9 opt-einsum 3.3.0 osqp 0.6.1 packaging 20.4 palettable 3.3.0 pandas 1.1.4 pandas-datareader 0.9.0 pandas-gbq 0.13.3 pandas-profiling 1.4.1 pandocfilters 1.4.3 panel 0.9.7 param 1.10.0 parso 0.7.1 pathlib 1.0.1 patsy 0.5.1 pexpect 4.8.0 pickleshare 0.7.5 Pillow 7.0.0 pip 19.3.1 pip-tools 4.5.1 plac 1.1.3 plotly 4.4.1 plotnine 0.6.0 pluggy 0.7.1 portpicker 1.3.1 prefetch-generator 1.0.1 preshed 3.0.4 prettytable 2.0.0 progressbar2 3.38.0 prometheus-client 0.9.0 promise 2.3 prompt-toolkit 1.0.18 protobuf 3.12.4 psutil 5.4.8 psycopg2 2.7.6.1 ptyprocess 0.6.0 py 1.9.0 pyarrow 0.14.1 pyasn1 0.4.8 pyasn1-modules 0.2.8 pycocotools 2.0.2 pycparser 2.20 pyct 0.4.8 pydata-google-auth 1.1.0 pydot 1.3.0 pydot-ng 2.0.0 pydotplus 2.0.2 PyDrive 1.3.1 pyemd 0.5.1 pyglet 1.5.0 Pygments 2.6.1 pygobject 3.26.1 pymc3 3.7 PyMeeus 0.3.7 pymongo 3.11.1 pymystem3 0.2.0 PyOpenGL 3.1.5 pyparsing 2.4.7 pyrsistent 0.17.3 pysndfile 1.3.8 PySocks 1.7.1 pystan 2.19.1.1 pytest 3.6.4 python-apt 1.6.5+ubuntu0.3 python-chess 0.23.11 python-dateutil 2.8.1 python-louvain 0.14 python-slugify 4.0.1 python-utils 2.4.0 pytz 2018.9 pyviz-comms 0.7.6 PyWavelets 1.1.1 PyYAML 3.13 pyzmq 20.0.0 qtconsole 5.0.1 QtPy 1.9.0 regex 2019.12.20 requests 2.23.0 requests-oauthlib 1.3.0 resampy 0.2.2 retrying 1.3.3 rpy2 3.2.7 rsa 4.6 scikit-image 0.16.2 scikit-learn 0.22.2.post1 scipy 1.4.1 screen-resolution-extra 0.0.0 scs 2.1.2 seaborn 0.11.0 Send2Trash 1.5.0 setuptools 50.3.2 setuptools-git 1.2 Shapely 1.7.1 simplegeneric 0.8.1 six 1.15.0 sklearn 0.0 sklearn-pandas 1.8.0 slugify 0.0.1 smart-open 3.0.0 snowballstemmer 2.0.0 sortedcontainers 2.3.0 spacy 2.2.4 Sphinx 1.8.5 sphinxcontrib-serializinghtml 1.1.4 sphinxcontrib-websupport 1.2.4 SQLAlchemy 1.3.20 sqlparse 0.4.1 srsly 1.0.4 statsmodels 0.10.2 sympy 1.1.1 tables 3.4.4 tabulate 0.8.7 tblib 1.7.0 tensorboard 2.3.0 tensorboard-plugin-wit 1.7.0 tensorboardcolab 0.0.22 tensorflow 2.3.0 tensorflow-addons 0.8.3 tensorflow-datasets 4.0.1 tensorflow-estimator 2.3.0 tensorflow-gcs-config 2.3.0 tensorflow-hub 0.10.0 tensorflow-metadata 0.25.0 tensorflow-privacy 0.2.2 tensorflow-probability 0.11.0 termcolor 1.1.0 terminado 0.9.1 testpath 0.4.4 text-unidecode 1.3 textblob 0.15.3 textgenrnn 1.4.1 Theano 1.0.5 thinc 7.4.0 tifffile 2020.9.3 toml 0.10.2 toolz 0.11.1 torch 1.7.0+cu101 torchsummary 1.5.1 torchtext 0.3.1 torchvision 0.8.1+cu101 tornado 5.1.1 tqdm 4.41.1 traitlets 4.3.3 tweepy 3.6.0 typeguard 2.7.1 typing-extensions 3.7.4.3 tzlocal 1.5.1 umap-learn 0.4.6 uritemplate 3.0.1 urllib3 1.24.3 vega-datasets 0.8.0 wasabi 0.8.0 wcwidth 0.2.5 webencodings 0.5.1 Werkzeug 1.0.1 wheel 0.35.1 widgetsnbextension 3.5.1 wordcloud 1.5.0 wrapt 1.12.1 xarray 0.15.1 xgboost 0.90 xkit 0.0.0 xlrd 1.1.0 xlwt 1.3.0 yellowbrick 0.9.1 zict 2.0.0 zipp 3.4.0 .",
            "url": "https://farley.metax.vision/blog/2020/12/06/migration.html",
            "relUrl": "/blog/2020/12/06/migration.html",
            "date": " • Dec 6, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://farley.metax.vision/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "WANDERING BETWEEN SIN AND DISCIPLINE, WHAT I CAN DO IS MERELY TO LOOK AROUND AND LINGER ON IN VANITY FAIR. . 　　　　　　　　　　　　　　　　　　　　　　　 — FOREVER AND EVER . Farley Lai was a researcher in the Machine Learning department at the NEC Laboratories America. His current research interest ranges from video understanding, reasoning to blockchains. Previous projects involve unsupervised defect detection for manufacturing, visual entailment tasks for multimodal reasoning between images and text as well as state of the art language grounding. He received his Ph.D. under the supervision of Prof. Octav Chipara in Computer Science at the University of Iowa. High performance stream processing to model the runtime behavior and improve resource efficiency of stream applications through compile-time analysis serves as his research foundation. His M.S. was completed with thesis on distributed mutual exclusion and scheduling fairness at the National Central University in Taiwan. Before pursuing a Ph.D., he had been working in the surveillance industry and led a project of developing video management software. . He is reachable via social networks. An up-to-date resume is available for reference. . Honors and Awards . 2022 Spot Recognition Award for $1000 to recognize successful POC demo at Haven for Hope | 2021 NEC Excellent Invention Award for US17/016260 | 2020 NEC Labs Business Contribution Award for Smart Video Surveillance in Retail | 2019 Spot Recognition Award for $1500 to recognize key role in NECX/Eigen initiation | 2015 SIGBED ESWEEK 2015 Student Travel Grant for $500 | 2015 DevDraft September Challenge Top 20 finalists and exclusively invited badge designer | 2014 DevDraft Number Challenge Top 10 finalists | 2014 NSF Travel Grant for $1500 | 2013 Best Student Paper Award at CBMS | Full tuition scholarship in Computer Science at the University of Iowa | . .",
          "url": "https://farley.metax.vision/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Creative",
          "content": "2015 DevDraft Badge Design . At the request of DevDraft, I designed the following achievement badges for the finals Oct’15 over the weekend. It was fun and creative. Sometimes it could be more challenging than solving algorithmic puzzles. However, this context switch is healthy and demonstrates my artistic sense is still functional. . Top10 | Top20 | Top30 | Finalist | Code Correctness | Attention to Details | Debugging | Advanced CS | . . 2002 Baloo Camp Logo and T-Shirt Design . I was a rover scout through my college at the National Tsing Hua University in Taiwan. Senior scout crew traditionally held the Baloo camp before graduation to pass down knowledge and skills. I designed the camp logo and T-shirt in appreciation of the bonding experience in our generation. . .",
          "url": "https://farley.metax.vision/creative/",
          "relUrl": "/creative/",
          "date": ""
      }
      
  

  

  
      ,"page4": {
          "title": "OSS",
          "content": "In the past few years of working at NEC Labs, I have managed to release several OSS pacakges on GitHub for ease of the deployment of a retail video surveillance POC. The design and organization follow the Dependency Inversion Principle (DIP) instead of direct dependencies on a particular deep learning framework such as PyTorch. A target ML application is supposed to invoke the APIs provided by the packages. While the best documentation is the code per se, several feature highlights are worth going through. Hopefully, one may find them useful for production ML applications. . ML . So far, the only backend is PyTorch and ML essentially mimics the APIs. Nonetheless, it is possible to replace with other alternatives such as TensorFlow. This is in case that the lastest release of PyTorch comes with incompatibility or even bugs. In that regard, it allows ML to quickly work around those potential issues before the official fix such taht the target ML application remains intact. . Flexible Configurations . The configuration APIs follows the YAML format with several enhancements: . Accept scientific notation without decimal point in case of YAML 1.1 | Support a custom YAML constructor !include for ease of hierarchical configuration management The imported YAML config is allowed to update its parent YAML config nodes | . | . Here is a sample app project with configuration files under configs/: . |____app | |____configs | | |____defaults.yml | | |____sites | | | |____site2.yml | | | |____site1.yml | | |____app.yml | |____src | | |____program.py . A minimal sample program.py is as follows to wrap its main(...) with the ML app launchar: . #!/usr/bin/env python def main(cfg): print(f&quot;Running main() with cfg={cfg}&quot;) if __name__ == &#39;__main__&#39;: from ml import app from ml.argparse import ArgumentParser parser = ArgumentParser() cfg = parser.parse_args() app.run(main, cfg) . Sample configuration files are placed under configs/. The top level one is configs/app.yml for the program to invoke with option --cfg: . $&gt; ./program.py --cfg configs/app.yml . Looking into configs/app.yml below, a custom !include constructor is supported to include a specific configuration file that updates its parent configurations. . import: defaults: app_site: !include defaults.yml app_site: !include sites/site1.yml app_platform: Apple M1 app_OS: MacOSX . configs/defaults.yml serves as the default site config as follows: . name: Little Planet Branch location: St. Louis, MO template: XXX . configs/sites/site1.yml is the configuration for a specific site that may overwrite the defualts: . name: site1 location: Santa Clara, CA note: Welcome to CA . Since app.yml includes site1.yml, site1.yml will update the configuration in defaults.yml as updating a Python dictionary. Therefore, the resulting configuration is as follows: . %&gt; src/program.py --cfg configs/app.yml Running main() with cfg={ &#39;__file__&#39;: PosixPath(&#39;configs/app.yml&#39;), &#39;app_OS&#39;: &#39;MacOSX&#39;, &#39;app_platform&#39;: &#39;Apple M1&#39;, &#39;app_site&#39;: { &#39;location&#39;: &#39;Santa Clara, CA&#39;, &#39;name&#39;: &#39;site1&#39;, &#39;note&#39;: &#39;Welcome to CA&#39;, &#39;template&#39;: &#39;XXX&#39;}, &#39;daemon&#39;: False, &#39;deterministic&#39;: False, &#39;dist&#39;: None, &#39;dist_backend&#39;: &#39;nccl&#39;, &#39;dist_no_sync_bn&#39;: False, &#39;dist_port&#39;: 25900, &#39;dist_url&#39;: &#39;env://&#39;, &#39;gpu&#39;: [], &#39;logfile&#39;: None, &#39;logging&#39;: False, &#39;no_gpu&#39;: False, &#39;rank&#39;: -1, &#39;seed&#39;: 1204, &#39;slurm_constraint&#39;: None, &#39;slurm_cpus_per_task&#39;: 4, &#39;slurm_export&#39;: &#39;&#39;, &#39;slurm_mem&#39;: &#39;32G&#39;, &#39;slurm_nodelist&#39;: None, &#39;slurm_nodes&#39;: 1, &#39;slurm_ntasks_per_node&#39;: 1, &#39;slurm_partition&#39;: &#39;gpu&#39;, &#39;slurm_time&#39;: &#39;0&#39;, &#39;world_size&#39;: -1} . Note only keys name and location are replced while template remains as is. The semantics for additional keys such as note is to merged with the parent configuration. Other key-value settings are specified by ml.argparse as default command line options for other features. Rather than adding too many command line options, one or more key-value settings in the configuration can be overwritten in the same syntax key=value following --cfg /path/to/config.yml in the command line. For example, to replace the value of app_site.location with San Jose, CA, the following command line suffices: . %&gt; src/program.py --cfg configs/app.yml app_site.location=&#39;San Jose, CA&#39; Running main() with cfg={ &#39;__file__&#39;: PosixPath(&#39;configs/app.yml&#39;), &#39;app_OS&#39;: &#39;MacOSX&#39;, &#39;app_platform&#39;: &#39;Apple M1&#39;, &#39;app_site&#39;: { &#39;location&#39;: &#39;San Jose, CA&#39;, &#39;name&#39;: &#39;site1&#39;, &#39;note&#39;: &#39;Welcome to CA&#39;, &#39;template&#39;: &#39;XXX&#39;}, ... . HDF5 Compression . When saving Python objects, depending on the suffixes, pickle, h5 and pytorch binaries are supported. If h5 is chosen to save sparse binary features, compression options such as zstd can be enabled to reduce storage significantly. . GPU Visibility . Deep learning programs tend to access GPUs in parallel. Managing GPU visibility is crucial to facilitate distributed training and other processing that require GPU access. ML provides simple app launcher APIs to support common GPU access options. . Daemon Mode . It is common to kick start a long running training process through a remote shell. Instead of figuring out how screen and nohup work, turning a process into a daemon to detach from the terminal is as simple as providing a command line option. The ML app launcher APIs deal with the underlying complexities as usual as running the same program in the foreground. . Distributed Training and Execution . Composing a distributed parallel program in Python can be daunting and error prone. The ML app launcher APIs support PyTorch and SLURM backends for training and general execution given command line options. The PyTorch backend assumes one GPU per worker process on one GPU node. The SLRUM backend supports a cluster environment and execution across multiple GPU nodes. . TensorRT Deployment . For production inference to be competitie, ML model deployment optimization is necessary to reduce the runtime cost. TensorRT is a popular backend for ML to support. The APIs make it straighforward to convert a pretrained model into its TensorRT counterpart. . Checkpoints from AWS/S3 and Google Drive . By default, PyTorch hub APIs only supports loading checkpoints from direct URLs. ML hub APIs further supports AWS/S3 and Google Drive for private or 3rd party checkpoint storage. This makes it easy for business deployment at a low cost. . ML-Vision . TBD . ML-WS . TBD . feedstocks . TBD .",
          "url": "https://farley.metax.vision/oss/",
          "relUrl": "/oss/",
          "date": ""
      }
      
  

  
      ,"page5": {
          "title": "Portfolio",
          "content": "Up to date publications and patents issued or in application can be found on Google Scholar. The portfolio is intended to demonstrate the highlights in selected research and development projects. . AI/ML . COMPOSER: Compositional Learning of Group Activity in Videos Honglu Zhou, Asim Kadav, Aviv Shamsian, Shijie Geng, Farley Lai, Long Zhao, Ting Liu, Mubbasir Kapadia, Hans Peter Graf Under Review, 2022 . Self-supervised Video Representation Learning with Cascade Positive Retrieval Cheng-En Wu, underline{Farley Lai}, Yu Hen Hu, Asim Kadav L3D-IVU at CVPR, 2022 [paper] [code] . SplitBrain: Hybrid Data and Model Parallel Deep Learning Farley Lai, Asim Kadav, Erik Kruus arXiv, 2021 [report] . Learning Higher-order Object Interactions for Keypoint-based Video Understanding Yi Huang, Asim Kadav, Farley Lai, Deep Patel, Hans Peter Graf SRVU at ICCV, 2021 [paper] . Hopper: Multi-hop Transformer for Spatiotemporal Reasoning H. Zhou, A. Kadav, Farley Lai, A. Niculescu-Mizil, M. Renqiang Min, M. Kapadia, Hans Peter Graf ICLR, 2021 [paper] [code] . 15 Keypoints Is All You Need Michael Snower, Asim Kadav, Farley Lai, Hans Peter Graf CVPR, 2020 [paper] . Contextual Grounding of Natural Language Phrases in Images Farley Lai, Ning Xie, Derek Doran, Asim Kadav ViGIL at NeurIPS, 2019 [paper] [code] . Visual Entailment: A Novel Task for Fine-grained Image Understanding Ning Xie, Farley Lai, Derek Doran, Asim Kadav ViGIL at NeurIPS, 2018 [paper] [code] . Mobile Sensing . Workload Shaping Energy Optimizations with Predictable Performance for Mobile Sensing Farley Lai, Marjan Radi, Octav Chipara, William G. Griswold IoTDI, 2018 [paper] . Stream Processing Optimizations for Mobile Sensing Applications Farley Lai, Octav Chipara Ph.D. Dissertation in CS, University of Iowa, 2017 [paper] . Static Memory Management for Efficient Mobile Sensing Applications Farley Lai, Daniel Schmidt, Octav Chipara EMSOFT, 2015 [paper] . CSense: A Stream-Processing Toolkit for High-Rate Mobile Sensing Applications Farley Lai, Syed Shabih Hasan, Austin Laugesen, Octav Chipara IPSN, 2014 [paper] . AudioSense: Enabling Real-time Evaluation of Hearing Aid Technology In-Situ Syed Shabih Hasan, Farley Lai, Octav Chipara, Yi-Hsien Wu Best Student Paper Award, CBMS, 2013 [paper] . Distributed Computing . Optimal Alternators with Reduced Space Complexity Farley Lai, Shing-Tsaan Huang Master Thesis in CS, National Central University, Taiwan, 2002 [paper] . Patents . 4 US patents issued and 12 in application as of 2022. . Learning Representations of Generalized Cross-modal Entailment Tasks Farley Lai, Asim Kadav, Ning Xie US11250299, 2022 . False Alarm Reduction System for Automatic Manufacturing Quality Control Alexandru Niculescu-Mizil, Renqiang Min, Eric Cosatto, Farley Lai, Hans Peter Graf, Xavier Fontaine US11087452, 2021 . Unsupervised Neighbor-preserving Embedding for Image Stream Visualization and Anomaly Detection Renqiang Min, Farley Lai, Eric Cosatto, Hans Peter Graf US10885627, 2021 . Unsupervised Image-based Anomaly Detection Using Multi-scale Context-dependent Deep Autoencoding Gaussian Mixture Model Alexandru Niculescu-Mizil, Renqiang Min, Eric Cosatto, Farley Lai, Hans Peter Graf, Xavier Fontaine US10853937, 2020 .",
          "url": "https://farley.metax.vision/portfolio/",
          "relUrl": "/portfolio/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://farley.metax.vision/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}